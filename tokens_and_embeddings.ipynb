{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from unstructured.partition.text import partition_text\n",
    "from unstructured.cleaners.core import group_broken_paragraphs\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "# tokenization and embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Chroma\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "# embedding projection\n",
    "import umap.umap_ as umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visulalization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "It is a relatively large .txt file with impracitcal paragraph splitting. We group the broken parapraphs together into chunks of 1500 characters, which correspond to roughly 1 actual paragraph.\n",
    "\n",
    "Additionally, we want the partition to later fit into the token splitter. The token splitter we will use has a max input length of 128 tokens. German has a token word ratio of roughly 2.1:1. The average German word has 6.3 characters.\n",
    "\n",
    "128 / 2.1 * 6.3 = 384 characters\n",
    "\n",
    "We are can increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = partition_text('data/Stein.txt', paragraph_grouper=group_broken_paragraphs, max_partition=384)\n",
    "element_strings = [str(el) for el in elements]\n",
    "print(\"\\n\\n\".join([el for el in element_strings][:5]))\n",
    "print(\"The book has been split into \" + str(len(element_strings)) + \" chunks.\")\n",
    "print(\"An element is \" + str(len(str(element_strings[0]))) + \" characters long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk refinement\n",
    "\n",
    "We now make sure that each chunk fits into the input lenght of the model we will use to embed our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=128, model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "token_split_texts = []\n",
    "for text in element_strings:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")\n",
    "print(token_split_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model Analysis\n",
    "\n",
    "### Does it matter what language your text has when deciding for an embedding model?\n",
    "\n",
    "We tokenize the chunks now with the tokenizer of the embedding model we will use.\n",
    "\n",
    "- The model uses SentencePiece tokenisation, which is a bit different from WordPiece or Byte Pair Encoding.\n",
    "- We still see sub words. White spaces are highlighted with underscores.\n",
    "- Sentence boundaries are marked with `<s>`\n",
    "- Subwords and single characters are recognizable\n",
    "- Is more on the language-agnostic side, as it does not rely on white spaces to separate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "tokenized_chunks = []\n",
    "for i, text in enumerate(token_split_texts[:10]):\n",
    "    # Tokenize each chunk\n",
    "    encoded_input = model.tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    # Convert token IDs back to tokens\n",
    "    tokens = model.tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0].tolist())\n",
    "    tokenized_chunks.append(tokens)\n",
    "    print(f\"Chunk {i}: {tokens}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the same now with a model that uses a SentenciePiece tokenizer.\n",
    "\n",
    "You should notice:\n",
    "- White spaces have been removed\n",
    "- Words that have been split into words can be connected with `##`\n",
    "- First tries to determine word boundaries like byte-pair encoding.\n",
    "- The start of a sentence is marked with `[CLS]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Sahajtomar/German-semantic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Token to Embedding\n",
    "\n",
    "Notice:\n",
    "- our text snippet has 110 tokens\n",
    "- the embedding has 384 dimensions\n",
    "- When calculating the embedding, the embedding model first calculates the 384 dimensional embedding for each individual token\n",
    "- depending on the model the individual vectors are then averaged, maxed or they take the embedding for the sentence boundary marker.\n",
    "- This allows us to end up with just one rather than 110 384 dimensional vectors per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw text\n",
    "print(token_split_texts[10])\n",
    "\n",
    "# tokens\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "print(\"Number of tokens: \", len(model.tokenizer(token_split_texts[10], padding=True, truncation=True, max_length=128, return_tensors='pt')[0]))\n",
    "\n",
    "# Embedding\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "print(embedding_function([token_split_texts[10]]))\n",
    "print(\"Vector dimensions: \", len(embedding_function([token_split_texts[10]])[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "chroma_collection = chroma_client.create_collection(\"Steint.txt\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Projections\n",
    "\n",
    "We retrieve all embeddings from our chroma collection.\n",
    "\n",
    "- UMAP (Uniform Manifold Approximation and Projection): reduces dimensionanality of a vector to project into a lower dimensionality space. Tyipically 2D or 3D vor visualisations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to apply the UMAP transformation to our data\n",
    "\n",
    "We will need to tranform multiple vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(embeddings, umap_transform):\n",
    "    umap_embeddings = np.empty((len(embeddings),2))\n",
    "    for i, embedding in enumerate(tqdm(embeddings)): \n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])\n",
    "    return umap_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hogwarts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed and project the query into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query_embedding = embedding_function(query)\n",
    "project_original_query = project_embeddings(original_query_embedding, umap_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the chroma_collection for documents related to \"Hogwarts\" and retrieve the top 5 results\n",
    "\n",
    "\n",
    "- Extract the embeddings from the results\n",
    "\n",
    "- Flatten the list of embeddings\n",
    "\n",
    "- Project the result embeddings using the umap_transform\n",
    "\n",
    "- Project the dataset embeddings using the umap_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_collection.query(query_texts=[\"Hogwarts\"], n_results=5, include=['documents', 'embeddings'])\n",
    "print(results['documents'][0])\n",
    "result_embeddings = results['embeddings']\n",
    "result_embeddings = [item for sublist in result_embeddings for item in sublist]\n",
    "projected_result_embeddings = project_embeddings(result_embeddings, umap_transform)\n",
    "projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_text(text, max_length=15):\n",
    "    \"\"\" Shortens text to max_length and adds an ellipsis if the text was shortened. \"\"\"\n",
    "    return (text[:max_length] + '...') if len(text) > max_length else text\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Scatter plots\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray', label='Dataset')\n",
    "plt.scatter(projected_result_embeddings[:, 0], projected_result_embeddings[:, 1], s=100, facecolors='none', edgecolors='g', label='Results')\n",
    "plt.scatter(project_original_query[:, 0], project_original_query[:, 1], s=150, marker='X', color='r', label='Original Query')\n",
    "\n",
    "# Assuming result_texts is an array of texts for the results\n",
    "# result_texts = ['text1', 'text2', ..., 'text5']\n",
    "\n",
    "for i, text in enumerate(results['documents'][0]):\n",
    "    if i < len(projected_result_embeddings):\n",
    "        plt.annotate(shorten_text(text), (projected_result_embeddings[i, 0], projected_result_embeddings[i, 1]), fontsize=8)\n",
    "\n",
    "# Assuming you have text for the original query\n",
    "original_query_text = 'Original Query Text'  # Replace with your actual text for the original query\n",
    "plt.annotate(shorten_text(original_query_text), (project_original_query[0, 0], project_original_query[0, 1]), fontsize=8)\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('Hogwarts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D-Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjusted UMAP transform for 3D projection\n",
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform_3d = umap.UMAP(n_components=3, random_state=0, transform_seed=0).fit(embeddings)\n",
    "\n",
    "def project_embeddings_3d(embeddings, umap_transform):\n",
    "    umap_embeddings = np.empty((len(embeddings), 3))\n",
    "    for i, embedding in enumerate(tqdm(embeddings)): \n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])[0]\n",
    "    return umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_original_query = project_embeddings_3d(original_query_embedding, umap_transform_3d)\n",
    "projected_result_embeddings = project_embeddings_3d(result_embeddings, umap_transform_3d)\n",
    "projected_dataset_embeddings = project_embeddings_3d(embeddings, umap_transform_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "projected_dataset_embeddings_3d = projected_dataset_embeddings\n",
    "projected_result_embeddings_3d = projected_result_embeddings\n",
    "project_original_query_3d = project_original_query\n",
    "\n",
    "# Scatter plots\n",
    "ax.scatter(projected_dataset_embeddings_3d[:, 0], projected_dataset_embeddings_3d[:, 1], projected_dataset_embeddings_3d[:, 2], s=10, color='gray', label='Dataset')\n",
    "ax.scatter(projected_result_embeddings_3d[:, 0], projected_result_embeddings_3d[:, 1], projected_result_embeddings_3d[:, 2], s=100, facecolors='none', edgecolors='g', label='Results')\n",
    "ax.scatter(project_original_query_3d[:, 0], project_original_query_3d[:, 1], project_original_query_3d[:, 2], s=150, marker='X', color='r', label='Original Query')\n",
    "\n",
    "# Annotations\n",
    "for i, text in enumerate(results['documents'][0]):\n",
    "    if i < len(projected_result_embeddings_3d):\n",
    "        ax.text(projected_result_embeddings_3d[i, 0], projected_result_embeddings_3d[i, 1], projected_result_embeddings_3d[i, 2], shorten_text(text), fontsize=8)\n",
    "\n",
    "ax.text(project_original_query_3d[0, 0], project_original_query_3d[0, 1], project_original_query_3d[0, 2], shorten_text(original_query_text), fontsize=8)\n",
    "\n",
    "ax.set_xlabel('X Axis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
